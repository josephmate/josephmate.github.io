---
layout: post
title: "3,200% CPU Utilization"
date: 2023-05-01 9:00
author: joseph
comments: true
categories: [Java, Race Condition, Threads, TreeMap, Red-Black Tree]
---

I received another high priority bug report and this time it was so messed up we hit
3,200% CPU utilization - all 32 cores on the host fully utilized!
[compared to the last bug where we only used 1 core, 100%](https://josephmate.github.io/2021-10-03-my-bug-used-up-100cpu-or-did-it/)


Fortunately, we were using Java 17 runtime which had thread dumps with CPU time!
Sorting by CPU time brought a bunch of threads that looked similar to this:

```
"Thread-0" #22 [14700] prio=5 os_prio=0 cpu=10359.38ms elapsed=11.49s tid=0x000001cdc35aaf60 nid=14700 runnable  [0x00000047cfffe000]
   java.lang.Thread.State: RUNNABLE
	at java.util.TreeMap.put(java.base@17.0.1/TreeMap.java:826)
	at java.util.TreeMap.put(java.base@17.0.1/TreeMap.java:534)
	at BusinessLogic.someFunction(BusinessLogic.java:29)
    ...
```

I make a quick conclusion about this and thought to look at BusinessLogic:29 based
on the stack trace and it looked like this:

```java
public void someFunction(SomeType relatedObject, List<SomeOtherType> unrelatedObjects) {
  ...
  for (SomeOtherType unrelatedObject : unrelatedObjects) {
    treeMap.put(relatedObject.a(), relatedObject.b()); // line 29
  }
  ...
}
```

That code is odd.
Notice we're iterating over `unrelatedObject`, but the body of the loop only used `relatedObject`.
The code can be reduced to simply:
```java
public void someFunction(SomeType relatedObject, List<SomeOtherType> unrelatedObjects) {
  ...
  treeMap.put(relatedObject.a(), relatedObject.b());
  ...
  // unrelatedObjects is used later on in the fuction so cannot be removed
}
```

There must have been some refactoring in the area and unrelatedObject wasn't used anymore. 
I prepare my unit test and ran before and after the fix.
I tried `treeMap` and `unrelatedObjects` with 1,000,000 entries, well exceeding what the application ever saw and was not able to reproduce the problem.
Assuming unrelatedObjects is size N and treeMap is size M, the complexity is O(NlgM).
So it makes sense that I was unable to reproduce the problem.
[You wouldn't really see one minute of execution time until 100 million to 1 billion](https://josephmate.github.io/PowersOf2/).

It must be something else.
I was certain treeMap and unrelatedObjects never exceed 1,000 entries.

I wasn't verify familar with the class so I started to look around,
focusing on `treeMap` and `unrelatedObjects` to see if my assumption that they
never exceed 1,000 holds. Could they be in the millions or even billions?

Then I noticed the definition of the TreeMap as :
```
// The field wasn't actually named treeMap.
private final Map<K,V> treeMap = new TreeMap<>();
```

That's scary.
There were multiple threads accessing the TreeMap, and it was unguarded.
At this point, I had an aha moment.
Could an unguarded treeMap cause 3,200% utilization?

# Experiment

```java
threads.add(new Thread(() -> {
    Random random = new Random();
    for(int j = 0; j < numUpdates; j++) {
        try {
            treeMap.put(random.nextInt(1000), random.nextInt(1000));
        } catch (NullPointerException e) {
            // let it keep going so we can reproduce the issue.
        }
    }
}));
```
[from SimpleRepro.java](https://github.com/josephmate/java-by-experiments/tree/main/tree_map_corruption/src/main/SimpleRepro.java)

That's crazy! I always thought of race conditions as corrupting the data. I never though it could cause performance issues.

![example cycle generated from TreeMap experiment](/assets/2023-08-20_cpu_util_3200/red_black_tree_cycle.gv.svg)

[Complete code to generate above graph](https://github.com/josephmate/java-by-experiments/tree/main/tree_map_corruption/src/main/ExploringTreeMap.java)


# Related Work

* Ivo Anjo writing to a java treemap concurrently can lead to an infinite loop during reads https://ivoanjo.me/blog/2018/07/21/writing-to-a-java-treemap-concurrently-can-lead-to-an-infinite-loop-during-reads/
* High CPU due to multiple Java threads accessing TreeMap simultaneously  https://access.redhat.com/solutions/58008
    * originally reported as far back as June 20 2011 https://web.archive.org/web/20190715204100/https://access.redhat.com/solutions/58008
* Java Process consumes more than 100% CPU https://stackoverflow.com/questions/56234865/java-process-consumes-more-than-100-cpu

I'm not the first person to write about this issue, but this article provides a
few new perspectives not previously discussed:

1. Practical looking code that that reproduces the issue.
2. a survey of languages that will exhibit this property
3. starting with a claim that only particular class of languages experience this
   issue and showing through experimentation that is false
1. a new approach to fixing TreeMap and red black tree to prevent this issue

If any of these interest you, please keep reading.

# That code is not realistic

Some might claim that my experiemtanl code is unrealistic?
Who ignores NPEs?
We could reproduce this problem with in conjunction with another common bug that supresses uncaught exceptions.

## Uncaught Exceptions in Executor

The below code also reproduces the issue, but with a thread pool.
```java
final ExecutorService pool = Executors.newFixedThreadPool(numThreads);
final TreeMap<Integer,Integer> treeMap = new TreeMap<>();

Random random = new Random();
for (int i = 0; i < numThreads*numUpdatesPerThread; i++) {
    pool.submit( () -> {
        treeMap.put(random.nextInt(10000), random.nextInt(10000));
    });
}

pool.shutdown();
pool.awaitTermination(1, TimeUnit.DAYS);
```
[from ExecutorUncaughtRepro.java](https://github.com/josephmate/java-by-experiments/tree/main/tree_map_corruption/src/main/ExecutorUncaughtRepro.java)

When you run it, you'll see it hang.
Take a thread dump and see the same symptoms:
```
"pool-1-thread-1" #22 [15356] prio=5 os_prio=0 cpu=17734.38ms elapsed=21.39s tid=0x0000023c45dd3e90 nid=15356 runnable  [0x000000780b4fe000]
   java.lang.Thread.State: RUNNABLE
	at java.util.TreeMap.put(java.base@19.0.1/TreeMap.java:826)
	at java.util.TreeMap.put(java.base@19.0.1/TreeMap.java:534)
	at ExecutorUncaughtRepro.lambda$main$0(ExecutorUncaughtRepro.java:33)
	at ExecutorUncaughtRepro$$Lambda$14/0x00000008010031f0.run(Unknown Source)
	at java.util.concurrent.Executors$RunnableAdapter.call(java.base@19.0.1/Executors.java:577)
	at java.util.concurrent.FutureTask.run(java.base@19.0.1/FutureTask.java:317)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@19.0.1/ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@19.0.1/ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(java.base@19.0.1/Thread.java:1589)

```
It's stuck on the TreeMap and really high CPU utilization.

However, when looking at standard out there is nothing!
The threadpool swallowed all the NPEs not giving any indication of problem. 
Unfortunately, this was the case in my situation.

When managing your own threadpools you need to make sure you have an uncaught exception handler and also make sure to operate on the futures it return. If you do `future.get()` you will get an `ExectionException` wrapping the NPE!

## Again with gRPC

Here we recreate a realistic scenario in gRPC that reproduces the problem.
The service is powered by an unguarded TreeMap.

```java
@Override
public void addReceipt(
    ReceiptProcessorServiceOuterClass.AddReceiptRequest req,
    StreamObserver<ReceiptProcessorServiceOuterClass.AddReceiptResponse> responseObserver
) {
    int timestamp = req.getTimestamp();
    int totalPrice = req.getTotalPrice();
    receipts.put(timestamp, totalPrice);
    ReceiptProcessorServiceOuterClass.AddReceiptResponse response = ReceiptProcessorServiceOuterClass.AddReceiptResponse.newBuilder().build();
    responseObserver.onNext(response);
    responseObserver.onCompleted();
}
```
[from GrpcRepro.java](https://github.com/josephmate/java-by-experiments/tree/main/tree_map_corruption/src/main/GrpcRepro.java)

Dumping the threads gives us:
```
"grpc-default-executor-23" #54 [8796] daemon prio=5 os_prio=0 cpu=18671.88ms elapsed=175.50s tid=0x00000168b6c707c0 nid=8796 runnable  [0x000000059fbfe000]
   java.lang.Thread.State: RUNNABLE
	at java.util.TreeMap.put(java.base@19.0.1/TreeMap.java:826)
	at java.util.TreeMap.put(java.base@19.0.1/TreeMap.java:534)
	at ReceiptProcessorServiceImpl.addReceipt(GrpcRepro.java:59)
	at ReceiptProcessorServiceGrpc$MethodHandlers.invoke(ReceiptProcessorServiceGrpc.java:185)
	at io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:346)
	at io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:860)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(java.base@19.0.1/ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(java.base@19.0.1/ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(java.base@19.0.1/Thread.java:1589)
```
showing that TreeMap.put() got stuck on an infinite loop.

# How did it happen? Rotations

My suspicion is that two threads independantly rotate the tree
in opposite directions, resulting in a cycle.
I also suspect that the NPE is necessary.
The problem will not reproduce without hitting an NPE.
I do not have a formula proof of this conjecture.

# Other languages

Java is not the only victim to this problem.
If the programming language has red black trees and permits accessing nulls without crashing, then it can happen.

| Language   | Affected | Explanation | Code |
|------------|----------|-------------|------|
| Java       | yes      | this whole article is based on this | TODO |
| Kotlin     | yes      | uses java's TreeMap     |  |
| C#         | yes      | [SortedDictionary](https://stackoverflow.com/questions/14909853/is-sorteddictionary-a-red-black-tree) used red black tree | TODO |
| Ruby       | no       | Used red black tree from [kanwei/algorithms](http://kanwei.github.io/algorithms/classes/Containers/RubyRBTreeMap.html) but was unable to reproduce the issue. I believe it might not be able to reproduce the problem due to the Global Interpreter Lock (GIL), and how it limits when threads can switch preventing such an interleaving of threads that cause an infinite loop.     | TODO |
| Go         | yes         | [has popular datastructures library](https://github.com/emirpasic/gods#redblacktree) but don't know enough about go's memory model. will it segfault or will it give an error I can ignore?     | TODO |
| Rust       |          | no red black tree. uses [BTree instead](https://doc.rust-lang.org/std/collections/struct.BTreeMap.html). also ownership model prevents this sort of issue, unless you use unsafe     |
| C++        | yes    | [used red-black tree](https://stackoverflow.com/questions/18414579/what-data-structure-is-inside-stdmap-in-c). I was expecting it to always segfault first preventing it from hitting the issue. | TODO |
| PHP        | no       | not in standard library and did not find any popular libraries   |
| Javscript  | no       | [multithreading model cannot share references](https://stackoverflow.com/questions/40028377/is-it-possible-to-achieve-multithreading-in-nodejs) | |
| Typescript | no       | same argument as javascript| |
| Python     | no       | no red-black tree in standard libary and popular libraries like [Sorted Containers do not use red black tree](https://grantjenks.com/docs/sortedcontainers/implementation.html). despite no red black tree, if I had run the experiment, I would expect to not to be able to reproduce for the same reason as ruby: the GIL. |
| Rust | no       | compiler prevented me | TODO |
| Elixir     | no       | Although there are many third party implementations of
the red black trees in Elixir (and Erlang), the programming model makes it
impossible: data structures are immutable and interactions between threads are
limited to message passing. |

## Languages without NPEs

I expected that languages without NPEs like C++, it would be impossible to
reproduce the issue.
Earlier, I made that claim that you cannot produce this issu without an NPE.
Secondly, in a language like C++, you segfault and your program crashes instead
of hitting an NPE.
As a result, there must be an interleaving of the threads that does not require
an exception!

# Easy Fix: Gaurd against concurrent modification

The easiest way to fix this was to wrap the TreeMap with a synchronizedMap or switch to ConncurrentHashMap and sort on demand. Following that fix the problem went away.

# Controversial Fix: Track visited nodes

Modify the red-black tree to record the nodes it has already visited.
The only requires an additional O(ln(n)) memory since it's limited by the height of the tree.
If we encounter a node that we already visited, we throw a ConcurrentModificationException.
This will not prevent the data corruption, but will prevent 100% cpu tilization from the infinite loop if someone makes that mistake again in the future.

```diff
diff --git a/tree_map_corruption/java/src/main/java/ProtectedTreeMap.java b/tree_map_corruption/java/src/main/java/ProtectedTreeMap.java
index 53c15bb..2713d5a 100644
--- a/tree_map_corruption/java/src/main/java/ProtectedTreeMap.java
+++ b/tree_map_corruption/java/src/main/java/ProtectedTreeMap.java
@@ -345,7 +345,9 @@ public class ProtectedTreeMap<K,V>
         @SuppressWarnings("unchecked")
             Comparable<? super K> k = (Comparable<? super K>) key;
         Entry<K,V> p = root;
+        IdentityHashMap<Entry<?,?>, Boolean> visited = new IdentityHashMap<>();
         while (p != null) {
+            visited.put(p, true);
             int cmp = k.compareTo(p.key);
             if (cmp < 0)
                 p = p.left;
@@ -353,6 +355,10 @@ public class ProtectedTreeMap<K,V>
                 p = p.right;
             else
                 return p;
+
+            if (visited.containsKey(p)) {
+                throw new ConcurrentModificationException("TreeMap corrupted. Loop detected");
+            }
         }
         return null;
     }
@@ -779,6 +785,7 @@ public class ProtectedTreeMap<K,V>
     }
 
     private V put(K key, V value, boolean replaceOld) {
+        IdentityHashMap<Entry<?,?>, Boolean> visited = new IdentityHashMap<>();
         Entry<K,V> t = root;
         if (t == null) {
             addEntryToEmptyMap(key, value);
@@ -790,6 +797,7 @@ public class ProtectedTreeMap<K,V>
         Comparator<? super K> cpr = comparator;
         if (cpr != null) {
             do {
+                visited.put(t, true);
                 parent = t;
                 cmp = cpr.compare(key, t.key);
                 if (cmp < 0)
@@ -803,12 +811,17 @@ public class ProtectedTreeMap<K,V>
                     }
                     return oldValue;
                 }
+
+                if (visited.containsKey(t)) {
+                    throw new ConcurrentModificationException("TreeMap corrupted. Loop detected");
+                }
             } while (t != null);
         } else {
             Objects.requireNonNull(key);
             @SuppressWarnings("unchecked")
             Comparable<? super K> k = (Comparable<? super K>) key;
             do {
+                                                               visited.put(t, true);
                 parent = t;
                 cmp = k.compareTo(t.key);
                 if (cmp < 0)
@@ -822,6 +835,10 @@ public class ProtectedTreeMap<K,V>
                     }
                     return oldValue;
                 }
+
+                if (visited.containsKey(t)) {
+                    throw new ConcurrentModificationException("TreeMap corrupted. Loop detected");
+                }
             } while (t != null);
         }
         addEntry(key, value, parent, cmp < 0);
```

# Mistakes Happen: Layered approach

Mistakes happen so it's important that multiple layers are implace to detect the issue.

## Alerts on NPEs

We lacked an alarm on any instance of an NPE.
We only had error rate alarms.
This NPE only occurs once per API handler worker thread before which was not enough to trigger our error rate alarms.
On top of that, none of the NPEs were logged because we had an unhandled exception in our Executor.

## Alerts on utilization anomalies

This is how we discovered the issue.
The bug was filed due to this alarm.

## Uncaught exceptions on Executors

If you add your work to an executor you must ensure you have an uncaught exception handler.
```java
AtomicInteger threadNumber = new AtomicInteger(1);
ThreadFactory customThreadFactory = new ThreadFactory() {
    @Override
    public Thread newThread(Runnable r) {
        Thread thread = new Thread(r);
        thread.setName("my-thread-pool-" + threadNumber.getAndIncrement());
        thread.setUncaughtExceptionHandler(
          (dyingThread, throwable) -> {
            logger.error("uncaught exception!", throwable);
          }
        );
        return thread;
    }
};

ExecutorService executor = Executors.newFixedThreadPool(2, customThreadFactory);
```

This code is kind of ugly so you're better off using

[apache commons'BasicThreadFactory](https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/concurrent/BasicThreadFactory.html):
```java
new BasicThreadFactory.Builder()
  .namingPattern("my-thread-pool-%d")
  .uncaughtExceptionHandler(
    (dyingThread, throwable) -> {
      logger.error("uncaught exception!", throwable);
    }
  )
  .build();
```
or [guava's ThreadFactoryBuilder](https://guava.dev/releases/19.0/api/docs/com/google/common/util/concurrent/ThreadFactoryBuilder.html):
```java
new ThreadFactoryBuilder()
  .setNameFormat("my-thread-pool-%d")
  .setUncaughtExceptionHandler(
    (dyingThread, throwable) -> {
      logger.error("uncaught exception!", throwable);
    }
  )
  .build()
```

Without a handler, the exception will be swallowed and none of your monitoring will be able to detect the issue.

# Conclusion

Mistakes happen.
Watch out, unprotected concurrent modification data corruption can present itself as infinite loops!
Despite making multiple mistakes, that hid the problem at multiple layers but not all.
As long as you adopt a layered approach, you will be able to respond quickly.

